Evaluation
==========
We evaluated our product with a number of relevant stakeholders on two separate occasions: once before the beta release, and once before the final release.

In the first case, we held a big meeting with some teachers, the director of the summer program, the general director and deputy director of CELFS and people responsible for admin and IT. We demonstrated the functionality of our website and received comments and constructive criticism from the attendees. We acted upon their feedback by making changes they recommended, including throwing an error if student ID is not in the database, allowing admins to export the marks as an excel file, hiding the overall mark in the review page and considering accessibility issues that might arise from the size of the text or the color scheme.

In the second case, our client asked some of her colleagues to spend thirty minutes to an hour with one of us, marking a Micro Research Report with the old system, marking another report of the same length with the new system and then filling in a short Google forms survey. For each participant we randomly selected which essay they should mark first using which system as our client expressed concerns that having already marked one essay would reduce the time needed for the second one. We got eight teachers to participate and we found that, on average, our system took 5.7% longer than the current system. However, this does not account for the time the current system requires to scan files and put marks in the database. After recording our client input marks in the database, we found that it takes about two minutes per essay. Adding that to the time it took to do the marking with the old system and recalculating, we found that our system is actually 7.5% faster. Although that is not massive, we are quite happy with it as it was the first time using the system and we are confident that the time needed would decrease with practice. Moreover, six of the eight teachers said they would rather use our system, one was on the fence, and only one said they would prefer the old system.

We observed the users and noted which parts of the website they struggled with to ensure they are explained sufficiently in the user manual. We also noted, based on the survey results, that, aside from some mistakes in the text displayed, which we fixed, there was little we could change without making some party unhappy. For example, in the big meeting it was agreed that the page for marking the essays should not display numerical marks to avoid bias, but some of the teachers in the second stage of the evaluation mentioned they would prefer to be able to see the numerical mark before submitting.
